{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggleの「Titanic: Mchine Learning from Disaster」をやってみる  \n",
    "[Kaggleの「Titanic: Mchine Learning from Disaster」ページはこちら](https://www.kaggle.com/c/titanic \"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['Survived'], axis=1)\n",
    "train_y =train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータは特徴量のみなので、そのままで良い\n",
    "test_x = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\n",
    "test_x = test_x.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# それぞれのカテゴリ変数にlabel encodingを適用する\n",
    "for c in ['Sex', 'Embarked']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[c].fillna('NA'))\n",
    "    train_x[c] = le.transform(train_x[c].fillna('NA'))\n",
    "    test_x[c] = le.transform(test_x[c].fillna('NA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=20, n_jobs=0, num_parallel_tree=1, random=71,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# モデルの作成および学習データを与えての学習\n",
    "model = XGBClassifier(n_estimators=20, random=71)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値を確率で出力\n",
    "pred = model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "# 予測値を2値に変換\n",
    "pred_label = np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用ファイルの作成\n",
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'], 'Survived':pred_label})\n",
    "submission.to_csv('submission_first.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各foldのスコアを保存するリスト\n",
    "scores_accuracy =[]\n",
    "scores_logloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "logloss: 0.4384, accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# クロスバリデーション\n",
    "# 学習データを４分割して１つをバリデーションデータとすることを繰り返す\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    # 学習データを学習データとバリデーションデータに分ける\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    \n",
    "    # モデルの学習\n",
    "    model = XGBClassifier(n_estimators=20, random=71)\n",
    "    model.fit(tr_x, tr_y)\n",
    "    \n",
    "    # 予測値を確率で出力\n",
    "    va_pred = model.predict_proba(va_x)[:, 1]\n",
    "    \n",
    "    # バリデーションでのスコアを計算\n",
    "    logloss = log_loss(va_y, va_pred)\n",
    "    accuracy = accuracy_score(va_y, va_pred > 0.5)\n",
    "    \n",
    "    # foldのスコアを保存する\n",
    "    scores_logloss.append(logloss)\n",
    "    scores_accuracy.append(accuracy)\n",
    "\n",
    "# 各foldのスコアの平均を出力する\n",
    "logloss = np.mean(scores_logloss)\n",
    "accuracy = np.mean(scores_accuracy)\n",
    "print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# チューニング候補とするパラメータを準備\n",
    "param_space = {\n",
    "    'max_depth':[3, 5, 7],\n",
    "    'min_child_weight':[1.0, 2.0, 4.0]\n",
    "}\n",
    "\n",
    "# 探索するハイパーパラメータの組み合わせ\n",
    "param_combinations = itertools.product(param_space['max_depth'], param_space[\"min_child_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "max_depth: 7, min_child_weight: 4.0\n"
     ]
    }
   ],
   "source": [
    "# 各パラメータの組み合わせとスコアを保存するリスト\n",
    "params = []\n",
    "scores = []\n",
    "\n",
    "# 各パラメータの組み合わせごとにクロスバリデーション\n",
    "for max_depth, min_child_weight in param_combinations:\n",
    "    score_folds=[]\n",
    "    \n",
    "    # クロスバリデーション\n",
    "    # 学習データを４分割して１つをバリデーションデータとすることを繰り返す\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    # 学習データを学習データとバリデーションデータに分ける\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    \n",
    "    # モデルの学習\n",
    "    model = XGBClassifier(n_estimators=20, random=71,\n",
    "                          max_depth=max_depth, min_child_weight=min_child_weight)\n",
    "    model.fit(tr_x, tr_y)\n",
    "    \n",
    "    # 予測値を確率で出力\n",
    "    va_pred = model.predict_proba(va_x)[:, 1]\n",
    "    \n",
    "    # バリデーションでのスコアを計算\n",
    "    logloss = log_loss(va_y, va_pred)\n",
    "    \n",
    "    # foldのスコアを保存する\n",
    "    score_folds.append(logloss)\n",
    "    \n",
    "    # 各foldのスコアを平均する\n",
    "    score_mean = np.mean(score_folds)\n",
    "    \n",
    "    # パラメータの組み合わせとスコアを保存\n",
    "    params.append((max_depth, min_child_weight))\n",
    "    scores.append(score_mean)\n",
    "    \n",
    "# 最もスコアが良いものをベストなパラメータとする\n",
    "best_idx = np.argsort(scores)[0]\n",
    "best_param = params[best_idx]\n",
    "print(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}')\n",
    "\n",
    "# max_depth: 7, min_child_weight: 4.0 がベスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { random } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# xgboostモデル\n",
    "model_xgb = XGBClassifier(n_estimators=20, random=71)\n",
    "model_xgb.fit(train_x, train_y)\n",
    "pred_xgb = model_xgb.predict_proba(test_x)[:, 1]\n",
    "\n",
    "# ロジスティック回帰モデル\n",
    "# xgboostとは異なる特徴量が必要なので別途train_x2, test_x2があることになっている\n",
    "# model_lr.fit(train_x2, train_y)\n",
    "# pred_lr = model_lr.predict_proba(test_x2)[:, 1]\n",
    "\n",
    "# 予測値の加重平均をとる\n",
    "# pred = pred_xgb * 0.8 + pred_lr * 0.2\n",
    "# pred_label = np.label = np.where(pred > 0.5, 1, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
